---
title: "Data Analysis"
author: "Catherine Cornella"
output: html_document
---

# Setup libraries
```{r Setup, message=FALSE, warning=FALSE}
library(dplyr)      #General Data wrangling
library(ggplot2)    #Plotting and analysis
library(readr)      #File reading and writing
library(stringr)    #String reading
library(knitr)      #Markdown file exporting
library(tidyr)      #Data formatting
library(lubridate)  #Date-Time Wrangling

#Establish General Import path: 
#If the data location is ever changed, it can be altered in this one location and hold true for every file. 
importPath="/data/airflow/analysis/"
```

# Import data

### Meteorological data

```{r Import:Meteor, message=FALSE, warning=FALSE}
path=paste(importPath, "MeteorDataDT.csv", sep="")
MeteorDataDT <- read_csv(path)
```

### Sensor Data

```{r Import:Sensor, message=FALSE, warning=FALSE}
path=paste(importPath, "cyclone-hx9-telescope_spider_south.csv", sep="")
cyc_df <- read_csv(path, skip=5)
path=paste(importPath, "darkthunder-dome_slit_bottom_horizontal.csv", sep="")
dark_df <- read_csv(path, skip=5)
path=paste(importPath, "freflow-mez_obsroom_horizontal.csv", sep="")
fre_df <- read_csv(path, skip=5)
path=paste(importPath, "picasso-mez_obsroom_vertical.csv", sep="")
pic_df <- read_csv(path, skip=5)
path=paste(importPath, "turbopanda-dome_slit_top_vertical.csv", sep="")
turbo_df <- read_csv(path, skip=5)
```

### Engineering Data

```{r Import:Engineering, message=FALSE, warning=FALSE}
# -- adamcomproom table -- 
#contains time, rack1, rack2, rack3
path=paste(importPath, "acrOutput.csv", sep="")
acr_df <- read_csv(path)

# -- adamtube table -- 
#contains time, mirroreast, mirrorwest, uppertubesouth, tubesnifseast
path=paste(importPath, "atOutput.csv", sep="")
at_df <- read_csv(path)

# -- boltwood table -- 
# contains time, temp, windspeed, skytempdiff
path=paste(importPath, "bwOutput.csv", sep="")
bw_df <- read_csv(path)

# -- cfht table -- 
# contains time, temp, windspeed, skytempdiff
path=paste(importPath, "cfhtOutput.csv", sep="")
cfht_df <- read_csv(path)

# -- tcs table -- 
# contains time, temp, windspeed, skytempdiff
path=paste(importPath, "tcsOutput.csv", sep="")
tcs_df <- read_csv(path)

# -- ups0 table -- 
# contains time, temp, windspeed, skytempdiff
path=paste(importPath, "upsOutput.csv", sep="")
ups_df <- read_csv(path)
```

# Tidy/Re-format Data

```{r}
#Meteorlogical data: 
#Narrow the dates down to our timeframe. 
weather_d <- MeteorDataDT %>% filter(MeteorDataDT$DateTime >= as.Date("2022-08-18") & MeteorDataDT$DateTime <= as.Date("2023-04-16") )

#Add all the Sensors into one dataframe.
sensorMaster <- rbind(cyc_df, dark_df, fre_df, pic_df, turbo_df)
```

# Analysis

Exploratory graph

```{r}
#Cn2 multiplied by a factor of 100,000,000,000 for simple ease of readability and scaling.
#Simple Cn2 values by sensor, big picture
sensorMaster %>%  
ggplot( aes(x=(Cn2*100000000000), color=sensor)) + 
  geom_histogram(binwidth=0.00005) + xlim(0,0.05) 

#Simple Cn2 values by sensor, zoom in level 1
sensorMaster %>% 
ggplot( aes(x=(Cn2*100000000000), color=sensor)) + 
  geom_histogram(binwidth=0.00005) + xlim(0,0.01) 

#Simple Cn2 values by sensor, zoom in level 2
sensorMaster %>%  
ggplot( aes(x=(Cn2*100000000000), color=sensor)) + 
  geom_histogram(binwidth=0.00005) + xlim(0,0.005) 

```

At a glance it looks like turbopanda has the most consistently low OT, with all other sensors holding a secondary spike. Given that Picasso was the longest running sensor and also has the secondary spike, baring any secondary causes, the relative concentration of the turbopanda data is probably not due to simply more data. picasso has a runtime of approximately 8 months (august to april), and turbo panda is only 3 less than that (august to january). 


```{r }
#create a data frame with average Cn2 data per day
scrap <- sensorMaster %>% mutate(daDate=date(dateTime)) %>% 
                        group_by(sensor, daDate)%>% 
                        mutate(Cn2=mean(Cn2)) 

ggplot(scrap, aes(x=(Cn2*100000000000), color=sensor)) + 
  geom_histogram(binwidth=0.00005) + xlim(0,0.005)

```

What's the sensor with the most optical turbulence? on average? 

When we compare the mirror temp to the optical turbulence what do we see?

(1) What is the average daytime and nighttime (or maybe nighttime+dome open) Cn2 values per sensor?
What are the corresponding standard deviations?  
Do these values change if you cut your sample size in half (first half and second half or odd samples v. even samples)?  
For nighttime dome open measurements (and maybe separately for closed dome measurements)  

```{r}
#make the dataframe: average Cn2 values per sensor, split between day and night, by hour. 

# Okay. The point here is to make the average values of the Cn2 values every hour. 
# So we first group by the sensor. this means any like sum thing we do won't be all of them, but will isolate them based on sensor 
# Then we create a new column with just the hour because we don't really care about the minutes of the night, and it was proving too difficult to do so. 
# Then we once again group by sensor, but also by hourTime, so that
# we can then take the average Cn2 value, and it will give us the average cn2 value at that time of night from that sensor. 

day_avg_byHour <- sensorMaster %>% group_by(sensor) %>% 
                            mutate(hourTime= hour(dateTime)) %>%
                            filter(hourTime >= 5 & hourTime <= 18) %>% 
                            group_by(sensor, hourTime) %>% 
                            mutate(std_dev =sd(Cn2)) %>% 
                            group_by(sensor, hourTime, std_dev) %>% 
                            summarize(hourAvg= mean(Cn2))
#plot
day_avg_byHour_plot <- day_avg_byHour %>% ggplot(aes(x=hourTime, color=sensor)) +
                            geom_line(aes(y=hourAvg )) + 
                            geom_line(aes(y=std_dev), linetype="dashed") + 
                            facet_wrap(~sensor, scales="fixed") 
#display
day_avg_byHour_plot

#make the dataframe: average Cn2 values per sensor, split between day and night. 
# night_avg_byHour <- sensorMaster %>% group_by(sensor) %>% 
#                             mutate(hourTime= hour(dateTime)) %>%
#                             #filter(hourTime <= 5 | hourTime >= 18) %>% 
#                             group_by(sensor, hourTime) %>% 
#                             summarize(hourAvg= mean(Cn2))
# #plot
# night_avg_byHour_plot <- night_avg_byHour %>% ggplot(aes(x=hourTime, y=hourAvg, color=sensor)) + 
#                             geom_line(linetype="dashed") + 
#                             geom_point()
# #display
# night_avg_byHour_plot
```

I note that everything so far has been seemingly ignoring the time discrepancies between all the sensors. 

Alright, we got distinct graphs. given that it's average values per hour across all entries, dunno what exactly we really learn from that. but there it is. 


(2) do the sensor values show any dependence on difference in temperature between the 
       a) mirror and the tube, 
or the b) mirror and the outside air,
or the c) tube and the outside air? 

We're gonna have to synthesize the engineering data into every 5 minutes to link it up properly. 
current thoughts are to 
a) straight up transpose the times to the nearest 5 minute interval (bad)
b) round all times to 5 minute interval and average/combine all values for those rows (best?)
c) create an entry for every minute based on the nearest entry, and then 
    i) discard the not-every-5-minutes times
    ii) average the surrounding times to every 5 minutes. 
    

```{r}
#start looking at the engineering data
#Save the time as a Date time (posix) object so we can round it safely later. 
acr_df <- acr_df %>% mutate(dateTime= as_datetime(time)) %>% arrange(dateTime) #every ten seconds 00
at_df  <- at_df %>% mutate(dateTime= as_datetime(time))%>% arrange(dateTime) #every ten seconds 00
bw_df  <- bw_df %>% mutate(dateTime= as_datetime(time))%>% arrange(dateTime) #every minute 00
cfht_df<- cfht_df %>% mutate(dateTime= as_datetime(time))%>% arrange(dateTime) #every five seconds starting at 03
tcs_df <- tcs_df %>% mutate(dateTime= as_datetime(time))%>% arrange(dateTime) #every 16 seconds. (why. just why.)
ups_df <- ups_df %>% mutate(dateTime= as_datetime(time))%>% arrange(dateTime) #every five seconds starting at 01
```

So the engineering data is in seconds. meaning it's best to simply take the values from within a certain range of it and average them to the nearest minute. 

``` {r}
#rounded_date rounds all times to the nearest time interval, in our case, 5 minutes. 
acr_df$dateTime <- round_date(acr_df$dateTime, unit="5 mins")
at_df$dateTime <- round_date(at_df$dateTime, unit="5 mins")
bw_df$dateTime <- round_date(bw_df$dateTime, unit="5 mins")
cfht_df$dateTime <- round_date(cfht_df$dateTime, unit="5 mins")
tcs_df$dateTime <- round_date(tcs_df$dateTime, unit="5 mins")
ups_df$dateTime <- round_date(ups_df$dateTime, unit="5 mins")

#At this point we still have a row for each second, so now we need to average all the values into one row for each minute. 

acr_df
at_df
bw_df
cfht_df
tcs_df
ups_df

```
```{r}
#By grouping by the dateTime, anything we do after that will do it just for each group. 
acr5_df <- acr_df %>% group_by(dateTime) %>% 
                      summarize(rack1=mean(rack1), 
                                rack2=mean(rack2), 
                                rack3=mean(rack3))
at5_df <- at_df %>% group_by(dateTime) %>% 
                      summarize(mirroreast=mean(mirroreast), 
                                mirrorwest=mean(mirrorwest), 
                                uppertubesouth=mean(uppertubesouth), 
                                tubesnifseast=mean(tubesnifseast))
bw5_df <- bw_df %>% group_by(dateTime) %>% 
                      summarize(bw_temp=mean(bw_temp), 
                                windspeed=mean(windspeed), 
                                skytempdiff=mean(skytempdiff))
cfht5_df <- cfht_df %>% group_by(dateTime) %>% 
                      summarize(cfht_temp=mean(cfht_temp), 
                                pressure=mean(pressure), 
                                windavgspd=mean(windavgspd), 
                                windavgdir=mean(windavgdir), 
                                windmaxspd=mean(windmaxspd), 
                                windmaxdir=mean(windmaxdir))
tcs5_df <- tcs_df %>% group_by(dateTime) %>% 
                      summarize(domeaz=mean(domeaz), 
                                ha=mean(ha), 
                                dec=mean(dec), 
                                slit=mean(slit))
ups5_df <- ups_df %>% group_by(dateTime) %>% 
                      summarize(ambienttemp=mean(ambienttemp) )
```

Alright, now let's bind all the engineering data into one dataframe. Easier to compare it all 

```{r}
#merge(x = df1, y = df2, by = "CustomerId", all = TRUE)
engineeringMaster <- merge(acr5_df, at5_df, by="dateTime", all=TRUE)
engineeringMaster <- merge(engineeringMaster, bw5_df, by="dateTime", all=TRUE)
engineeringMaster <- merge(engineeringMaster, cfht5_df, by="dateTime", all=TRUE)
engineeringMaster <- merge(engineeringMaster, tcs5_df, by="dateTime", all=TRUE)
engineeringMaster <- merge(engineeringMaster, ups5_df, by="dateTime", all=TRUE)
engineeringMaster

```


(3) versus time of day, and 
(4) versus the direction of the dome with respect to the wind direction reported by the CFHT/Gemini weather tower?
