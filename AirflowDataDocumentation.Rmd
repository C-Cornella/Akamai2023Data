---
title: "Airflow Data Documentation"
author: "Catherine Cornella"
date: "2023-06-22"
output: html_document
---

## AIRFLOW Sensor Data processing

Detailed version of sensorDataframing1.R:  

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(dplyr)      #General Data wrangling
library(readr)      #File reading and writing
library(stringr)    #String reading
library(knitr)      #Markdown file exporting
library(tidyr)      #Data formatting
library(lubridate)  #Date-Time Wrangling
library(FITSio)     #Fits file parsing -- Probably unnecessary, will likely remove later
```

## Export Path Argument

```{r ExportPaths, eval=FALSE}
#Include optional argument for file export path
args = commandArgs(trailingOnly=TRUE)
#If no argument is supplied
if (length(args)==0) {
  #Default value of path
  exportPath <- ""
} else if (length(args)==1) {
  # our new export path
  exportPath=args[1]
}
```


## Data Import

The code is designed to go directly to the `/data/airflow/reduce` directory, and parse the `textAF_sensorName_date.txt` files from each day into one cohesive .csv for each sensor. 

### Step 1: Specify the path: 

The path leads to the folder of reduced data for the sensor. It is assumed the directory structure is `/data/airflow`, containing a folder of reduced data (`reduce`), which contains a folder for each airflow sensor (ex. `turbopanda`), which contains a folder for each given date (ex. `2022-08-18`), which contains .fits files and one .txt file (ex. `textAF_turbopanda_2022-08-18.txt`). An example path to a specific .txt, then, is `/data/airflow/reduce/turbopanda/2022-08-18/textAF_turbopanda_2022-08-18`. 

To avoid a separate path to each .txt file for each day for each sensor, the code starts in the directory of a given sensor, and creates a list of all files of .txt type. This reduces our paths to just 5, one per sensor. The path variables set below should direct to the folder for each sensor, one level above the individual date folders. 

```{r DataImport: Step 1, message=FALSE, warning=FALSE}

#Path to files: unique path for each airflow unit
# -- This way the script navigates directly to the appropriate directory and doesn't need to be copied into the R script folder --
# -- Shouldn't need to change any of these unless the file organization changes
filePathCy <- "/data/airflow/reduce/cyclone-hx9"
filePathDark <- "/data/airflow/reduce/darkthunder"
filePathFre <- "/data/airflow/reduce/freflow"
filePathPic <- "/data/airflow/reduce/picasso"
filePathTurbo <- "/data/airflow/reduce/turbopanda"
```

### Step 2: Specify the column names: 

The column names are taken from Sensor Data Format.txt, which offers further information on what each variable denotes specifically. `npha_Neo3.pro` creates 24 columns in the .txt, thus 24 column names. 

``` {r DataImport: Step 2, message=FALSE, warning=FALSE}
#Column Names for sensor data. 
# -- Taken from the Sensor Data Format.txt file -- 
# -- Names provided from the npha_Neo3.pro reduction routine: Shouldn't need to be changed unless the reduction routine is changed -- 
colNames <- c("year", "month", "day", "floatDate", "floattime", "r0_1", "Cn2", "residual_Kolmo", 
              "r0Kalman", "L0Kalman", "residual_Kalman", "r0power", "r0expo", 
              "residual_power", "r0max", "r0min", "Cn2max", "Cn2min",
              "r0noTT(0)", "Cn2noTT", "r0noTT(1)", "residual_KolmonoTT", "imamax", 
              "npixsat", "offsets(0)", "offsets(1)", "flagdata") 

```

### Step 3: Create the lists of file names

Using the paths created in step 1, we create the lists of file names. Each sensor has a separate list. 

``` {r DataImport: Step 3, message=FALSE, warning=FALSE}
#Creation of lists of Files for each sensor
# -- A single command saves each .txt as a seperate dataframe in a list. -- 
# -- Function Arguments: 
#      path: where to look for files
#      pattern: What to match
#      all.files: Include hidden files in search
#      full.names: Include absolute path name in filename
#      recursive: Search all subFolders
fileListCy <- list.files(path=filePathCy, 
                            pattern=".txt", 
                            all.files=TRUE, 
                            full.names=TRUE, 
                            recursive=TRUE)
fileListDark <- list.files(path=filePathDark, 
                            pattern=".txt", 
                            all.files=TRUE, 
                            full.names=TRUE, 
                            recursive=TRUE)
fileListFre <- list.files(path=filePathFre, 
                            pattern=".txt", 
                            all.files=TRUE, 
                            full.names=TRUE, 
                            recursive=TRUE)
fileListPic <- list.files(path=filePathPic, 
                            pattern=".txt", 
                            all.files=TRUE, 
                            full.names=TRUE, 
                            recursive=TRUE)
fileListTurbo <- list.files(path=filePathTurbo, 
                            pattern=".txt", 
                            all.files=TRUE, 
                            full.names=TRUE, 
                            recursive=TRUE)
```

### Step 4: Import data

Using lapply and read.table, the code creates a list of dataframes, one dataframe per .txt file, and one list per sensor. The code assumes the .txt files have no headers, and that they have 24 columns. 

Note: If any of the .txt files do not have 24 columns, the code will fail. 

```{r DataImport: Step 4, message=FALSE, warning=FALSE}
#Import data
# -- Runs read.table on every file in the file list, saving each dataframe in a list of dataframes. --
# -- Function Arguments
#    lapply: 
#        fileListExample: List to execute on
#        function to execute: Read.table
#             x: element to read
#             header: Assume no header in the files
#             col.names: Read in data assigning these names to each column
dataListCy <- lapply(fileListCy, function(x) read.table(x, header = FALSE, col.names = colNames) )  
dataListDark <- lapply(fileListDark, function(x) read.table(x, header = FALSE, col.names = colNames) )
dataListFre <- lapply(fileListFre, function(x) read.table(x, header = FALSE, col.names = colNames) )
dataListPic <- lapply(fileListPic, function(x) read.table(x, header = FALSE, col.names = colNames) )
dataListTurbo <- lapply(fileListTurbo, function(x) read.table(x, header = FALSE, col.names = colNames) )
```

### Step 5: Bind dataframes

Each list of dataframes is converted into a single dataframe using `bind_rows`, which takes the list of dataframes as the only argument. The end result is a single dataframe for each sensor, containing all information from that sensor. 

``` {r DataImport: Step 5, message=FALSE, warning=FALSE}
#Join individuals into masterDataframe
# -- bind_rows takes a list of dataframes and combines them into one, appending rows to the end of the dataFrame. --
dataFrameCy <- bind_rows(dataListCy) 
dataFrameDark <- bind_rows(dataListDark) 
dataFrameFre <- bind_rows(dataListFre) 
dataFramePic <- bind_rows(dataListPic) 
dataFrameTurbo <- bind_rows(dataListTurbo) 
```


## Data Tidying

Data is rarely in a perfect form when first imported. We convert to a Date-time object, and add a column for the sensor name. The sensor name will be useful when comparing data from different sensors and graphing results. The simplest time to add that is now. 

```{r DataTidying: Step 1, message=FALSE, warning=FALSE}
#Convert from floatTime to date-time object
# -- floatTime is the hour.(minute/60 + seconds/3600)
# -- paste to turn the columns into a string that can be parsed by ymd_hm()
# -- select to drop the excess columns
dataFrameCy <- dataFrameCy %>% mutate(hour = floor(floattime),
                                      minute=as.integer(round((floattime-hour)*60)) ) %>% 
                           mutate(dateTime= ymd_hm(paste(year, month, day, hour, minute), tz="HST") ) %>% 
                           select(dateTime, r0_1, Cn2, residual_Kolmo, r0Kalman, L0Kalman, residual_Kalman,
                                  r0power, r0expo, residual_power, r0max, r0min, Cn2max, Cn2min, r0noTT.0.,
                                  Cn2noTT, r0noTT.1., residual_KolmonoTT, imamax, npixsat, offsets.0.,
                                  offsets.1., flagdata) 
dataFrameDark <- dataFrameDark %>%  mutate(hour = floor(floattime),
                                           minute=as.integer(round((floattime-hour)*60)) ) %>% 
                           mutate(dateTime= ymd_hm(paste(year, month, day, hour, minute), tz="HST") ) %>% 
                           select(dateTime, r0_1, Cn2, residual_Kolmo, r0Kalman, L0Kalman, residual_Kalman,
                                  r0power, r0expo, residual_power, r0max, r0min, Cn2max, Cn2min, r0noTT.0.,
                                  Cn2noTT, r0noTT.1., residual_KolmonoTT, imamax, npixsat, offsets.0.,
                                  offsets.1., flagdata) 
dataFrameFre <- dataFrameFre %>%  mutate(hour = floor(floattime),
                                         minute=as.integer(round((floattime-hour)*60)) ) %>% 
                           mutate(dateTime= ymd_hm(paste(year, month, day, hour, minute), tz="HST") ) %>% 
                           select(dateTime, r0_1, Cn2, residual_Kolmo, r0Kalman, L0Kalman, residual_Kalman,
                                  r0power, r0expo, residual_power, r0max, r0min, Cn2max, Cn2min, r0noTT.0.,
                                  Cn2noTT, r0noTT.1., residual_KolmonoTT, imamax, npixsat, offsets.0.,
                                  offsets.1., flagdata) 
dataFramePic <- dataFramePic %>% mutate(hour = floor(floattime),
                                        minute=as.integer(round((floattime-hour)*60)) ) %>% 
                           mutate(dateTime= ymd_hm(paste(year, month, day, hour, minute), tz="HST") ) %>% 
                           select(dateTime, r0_1, Cn2, residual_Kolmo, r0Kalman, L0Kalman, residual_Kalman,
                                  r0power, r0expo, residual_power, r0max, r0min, Cn2max, Cn2min, r0noTT.0.,
                                  Cn2noTT, r0noTT.1., residual_KolmonoTT, imamax, npixsat, offsets.0.,
                                  offsets.1., flagdata) 
dataFrameTurbo <- dataFrameTurbo %>% mutate(hour = floor(floattime),
                                            minute=as.integer(round((floattime-hour)*60)) ) %>% 
                           mutate(dateTime= ymd_hm(paste(year, month, day, hour, minute), tz="HST") ) %>% 
                           select(dateTime, r0_1, Cn2, residual_Kolmo, r0Kalman, L0Kalman, residual_Kalman,
                                  r0power, r0expo, residual_power, r0max, r0min, Cn2max, Cn2min, r0noTT.0.,
                                  Cn2noTT, r0noTT.1., residual_KolmonoTT, imamax, npixsat, offsets.0.,
                                  offsets.1., flagdata) 


```

```{r DataTidying: Step 2, message=FALSE, warning=FALSE}
#Add the Sensor name as a column and the location 
dataFrameCy <- dataFrameCy %>% mutate(sensor="cyclone-hx9", location="1")
dataframeDark <- dataFrameDark %>% mutate(sensor ="darkthunder", location="1")
dataFrameFre <- dataFrameFre %>% mutate(sensor="freflow", location="1")
dataFramePic <- dataFramePic %>% mutate(sensor="picasso", location="1")
dataFrameTurbo <- dataFrameTurbo %>% mutate(sensor="turbopanda", location="1")
```


## Data Export

With the data now in proper form for easier analysis, we export each sensor's dataframe as a unique .csv

### Step 1: Specify Paths

Here we specify the export paths of the .csvs, so that should it be wished, the location is not the same directory the R script was executed from. Changing the default path is not necessary but unlikely to be optimal. The paste function appends the name of the file to the specified path. This function by default adds a space between the strings being concatenated, but the additional argument `sep` overrides that with the user's preference. 

```{r DataExport: Step 1, message=FALSE, warning=FALSE}
#Default value of path
exportPath <- ""

#INSERT DESIRED PATH HERE
#exportPath <- "/data/airflow/reduce/csv"

#Add the export path to the beginning of the specific .csv name
# -- Additional argument: sep: added to remove the usually added space
exportPathCy <-paste(exportPath, "cyclone-hx9Data.csv", sep="")
exportPathDark <-paste(exportPath, "darkthunderData.csv", sep="")
exportPathFre <-paste(exportPath, "freflowData.csv", sep="")
exportPathPic <-paste(exportPath, "picassoData.csv", sep="")
exportPathTurbo <-paste(exportPath, "turbopandaData.csv", sep="")

```

### Step 2: Export as .csv

Using the paths created above, the dataframes are exported to the desired locations as .csvs. 

``` {r DataExport: Step 2, message=FALSE, warning=FALSE}
#Export dataframe as a .csv
write.csv(dataFrameCy, exportPathCy, row.names=FALSE)
write.csv(dataFrameDark, exportPathDark, row.names=FALSE)
write.csv(dataFrameFre, exportPathFre, row.names=FALSE)
write.csv(dataFramePic, exportPathPic, row.names=FALSE)
write.csv(dataFrameTurbo, exportPathTurbo, row.names=FALSE)
```
